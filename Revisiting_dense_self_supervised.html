<!DOCTYPE html>
<html>
    <head>
        <title>Revisiting Dense Self-Supervised Learning for Medical Image Segmentation: Attention Mechanisms and Interpretability
</title>
        <meta charset="utf-8" />
      

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css">

  <!-- <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.0/jquery.min.js"></script> -->

  <!-- <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js"></script> -->

  <!-- <link href='https://fonts.googleapis.com/css?family=Oswald:700' rel='stylesheet' type='text/css'> -->

  <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=default'></script>


    </head>
    <body>
       
      <h1>Revisiting Dense Self-Supervised Learning for Medical Image Segmentation: Attention Mechanisms and Interpretability</h1>
       <ul>
    <h4>
        <p>
            Supervisor: CUEVAS VILLARMIN Carlos
            <br> Contact: <a href="mailto:ccuevasvillarmin@gmail.com">ccuevasvillarmin@gmail.com</a>
        </p>
        
    </h4>
     <h3>
            Description: </h3>
          
        Self-supervised learning (SSL) has become a powerful paradigm in medical image analysis, enabling the use of large-scale unlabeled data to pre-train models that can be fine-tuned on limited annotations. 
        <br>The recent work “Dense Self-Supervised Learning for Medical Image Segmentation” (Seince et al., 2024) highlights the potential of dense SSL pretext tasks to improve segmentation performance. 
        <br>However, this approach does not explicitly address the role of attention mechanisms in representation learning, nor the interpretability of learned features.

This project builds on that foundation with three objectives:
<ul>
<li> Reproduce and validate some of the baseline results (Table 1: Fully-Supervised Learning and proposed SSL).</li>
<li> Attention Mechanisms: Review the literature and implement different attention strategies within SSL and fine-tuning. For example, including direct supervision of attention maps guided by historical errors.</li>
<li> Interpretability: Analyze attention map outputs to evaluate their role in model transparency and performance.</li>

The project aims to deepen understanding of how attention interacts with SSL in medical imaging, while emphasizing interpretability as a key step toward accurate and trustworthy segmentation systems.


</ul>
 <h4> <a href="index.html">Back to the list</a> </h4>
    </body>
    
</html>

